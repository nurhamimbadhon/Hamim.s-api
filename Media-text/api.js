const express = require("express");
const multer = require("multer");
const fs = require("fs");
const path = require("path");
const ffmpeg = require("fluent-ffmpeg");

const router = express.Router();
const upload = multer({ dest: "uploads/" });

// Mock transcription responses for different languages
const mockResponses = {
  en: "Hello, this is a sample transcription in English. The audio has been processed successfully.",
  bn: "à¦¹à§à¦¯à¦¾à¦²à§‹, à¦à¦Ÿà¦¿ à¦¬à¦¾à¦‚à¦²à¦¾à¦¯à¦¼ à¦à¦•à¦Ÿà¦¿ à¦¨à¦®à§à¦¨à¦¾ à¦Ÿà§à¦°à¦¾à¦¨à§à¦¸à¦•à§à¦°à¦¿à¦ªà¦¶à¦¨à¥¤ à¦…à¦¡à¦¿à¦“ à¦¸à¦«à¦²à¦­à¦¾à¦¬à§‡ à¦ªà§à¦°à¦•à§à¦°à¦¿à¦¯à¦¼à¦¾ à¦•à¦°à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡à¥¤",
  hi: "à¤¨à¤®à¤¸à¥à¤¤à¥‡, à¤¯à¤¹ à¤¹à¤¿à¤‚à¤¦à¥€ à¤®à¥‡à¤‚ à¤à¤• à¤¨à¤®à¥‚à¤¨à¤¾ à¤Ÿà¥à¤°à¤¾à¤‚à¤¸à¤•à¥à¤°à¤¿à¤ªà¥à¤¶à¤¨ à¤¹à¥ˆà¥¤ à¤‘à¤¡à¤¿à¤¯à¥‹ à¤•à¥‹ à¤¸à¤«à¤²à¤¤à¤¾à¤ªà¥‚à¤°à¥à¤µà¤• à¤ªà¥à¤°à¥‹à¤¸à¥‡à¤¸ à¤•à¤¿à¤¯à¤¾ à¤—à¤¯à¤¾ à¤¹à¥ˆà¥¤",
  pt: "OlÃ¡, esta Ã© uma transcriÃ§Ã£o de exemplo em portuguÃªs. O Ã¡udio foi processado com sucesso.",
  ko: "ì•ˆë…•í•˜ì„¸ìš”, ì´ê²ƒì€ í•œêµ­ì–´ ìƒ˜í”Œ ì „ì‚¬ìž…ë‹ˆë‹¤. ì˜¤ë””ì˜¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.",
  banglish: "Hello, ei ekta banglish e sample transcription. Audio successfully process kora hoyeche."
};

// Word banks for generating realistic transcriptions
const wordBanks = {
  en: [
    "Hello", "thank", "you", "please", "how", "are", "you", "today",
    "this", "is", "a", "test", "of", "speech", "recognition", "system",
    "audio", "quality", "sounds", "good", "clear", "voice", "recording"
  ],
  bn: [
    "à¦¹à§à¦¯à¦¾à¦²à§‹", "à¦§à¦¨à§à¦¯à¦¬à¦¾à¦¦", "à¦†à¦ªà¦¨à¦¿", "à¦•à§‡à¦®à¦¨", "à¦†à¦›à§‡à¦¨", "à¦†à¦œ", "à¦à¦Ÿà¦¿", "à¦à¦•à¦Ÿà¦¿",
    "à¦¸à§à¦ªà¦¿à¦š", "à¦°à¦¿à¦•à¦—à¦¨à¦¿à¦¶à¦¨", "à¦¸à¦¿à¦¸à§à¦Ÿà§‡à¦®", "à¦…à¦¡à¦¿à¦“", "à¦—à§à¦£à¦®à¦¾à¦¨", "à¦­à¦¾à¦²", "à¦¸à§à¦ªà¦·à§à¦Ÿ"
  ],
  hi: [
    "à¤¨à¤®à¤¸à¥à¤¤à¥‡", "à¤§à¤¨à¥à¤¯à¤µà¤¾à¤¦", "à¤†à¤ª", "à¤•à¥ˆà¤¸à¥‡", "à¤¹à¥ˆà¤‚", "à¤†à¤œ", "à¤¯à¤¹", "à¤à¤•",
    "à¤¸à¥à¤ªà¥€à¤š", "à¤°à¤¿à¤•à¤—à¥à¤¨à¤¿à¤¶à¤¨", "à¤¸à¤¿à¤¸à¥à¤Ÿà¤®", "à¤‘à¤¡à¤¿à¤¯à¥‹", "à¤—à¥à¤£à¤µà¤¤à¥à¤¤à¤¾", "à¤…à¤šà¥à¤›à¥€", "à¤¸à¥à¤ªà¤·à¥à¤Ÿ"
  ],
  pt: [
    "OlÃ¡", "obrigado", "vocÃª", "como", "estÃ¡", "hoje", "este", "Ã©",
    "um", "sistema", "de", "reconhecimento", "de", "fala", "Ã¡udio", "qualidade"
  ],
  ko: [
    "ì•ˆë…•í•˜ì„¸ìš”", "ê°ì‚¬í•©ë‹ˆë‹¤", "ë‹¹ì‹ ", "ì–´ë–»ê²Œ", "ì˜¤ëŠ˜", "ì´ê²ƒì€", "ìŒì„±",
    "ì¸ì‹", "ì‹œìŠ¤í…œ", "ì˜¤ë””ì˜¤", "í’ˆì§ˆ", "ì¢‹ì€", "ëª…í™•í•œ"
  ],
  banglish: [
    "Hello", "dhonnobad", "apni", "kemon", "achen", "ajke", "ei", "ekta",
    "speech", "recognition", "system", "audio", "quality", "bhalo", "clear"
  ]
};

// Analyze audio properties
function analyzeAudioProperties(audioPath) {
  return new Promise((resolve, reject) => {
    ffmpeg.ffprobe(audioPath, (err, metadata) => {
      if (err) {
        resolve({ duration: 5, sampleRate: 16000 }); // Default values
      } else {
        const duration = metadata.format.duration || 5;
        const sampleRate = metadata.streams[0]?.sample_rate || 16000;
        resolve({ duration, sampleRate });
      }
    });
  });
}

// Generate realistic transcription based on audio properties
function generateRealisticTranscription(audioProperties, lang) {
  const { duration } = audioProperties;
  const wordsPerSecond = 1.5; // Average speaking rate
  const estimatedWords = Math.max(3, Math.floor(duration * wordsPerSecond));
  
  const words = wordBanks[lang] || wordBanks.en;
  const selectedWords = [];
  
  // Generate words based on estimated count
  for (let i = 0; i < estimatedWords; i++) {
    const randomIndex = Math.floor(Math.random() * words.length);
    selectedWords.push(words[randomIndex]);
  }
  
  return selectedWords.join(" ");
}

// Apply language-specific post-processing
function applyPostProcessing(text, lang) {
  if (lang === "hi") {
    return text
      .replace(/Ä/g, "aa")
      .replace(/Ä«/g, "ee")
      .replace(/Å«/g, "oo")
      .replace(/á¹…/g, "n")
      .replace(/á¹­/g, "t")
      .replace(/á¸/g, "d")
      .replace(/á¹‡/g, "n")
      .replace(/Å›/g, "sh")
      .replace(/á¹£/g, "sh")
      .replace(/á¸¥/g, "h");
  }
  return text;
}

// Main transcription endpoint
router.post("/transcribe", upload.single("media"), async (req, res) => {
  const lang = req.body.lang || "en";
  const filePath = req.file.path;
  const audioPath = `${filePath}.wav`;

  try {
    console.log(`ðŸŽµ Processing audio file for language: ${lang}`);
    
    // Convert to WAV format
    await new Promise((resolve, reject) => {
      ffmpeg(filePath)
        .audioCodec("pcm_s16le")
        .audioFrequency(16000)
        .format("wav")
        .on("end", () => {
          console.log("âœ… Audio conversion completed");
          resolve();
        })
        .on("error", (err) => {
          console.error("âŒ Audio conversion failed:", err);
          reject(err);
        })
        .save(audioPath);
    });

    // Analyze audio properties
    const audioProperties = await analyzeAudioProperties(audioPath);
    console.log(`ðŸ“Š Audio analysis: ${audioProperties.duration}s duration`);

    // Generate transcription
    let text;
    if (audioProperties.duration > 0.5) {
      text = generateRealisticTranscription(audioProperties, lang);
    } else {
      text = mockResponses[lang] || mockResponses.en;
    }

    // Apply post-processing
    const processedText = applyPostProcessing(text, lang);

    console.log(`âœ… Transcription completed: ${processedText.substring(0, 50)}...`);

    res.json({
      lang,
      text: processedText,
      duration: audioProperties.duration,
      wordCount: processedText.split(" ").length,
      processingTime: new Date().toISOString(),
      note: "Mock transcription - configure a real speech service for production use"
    });

  } catch (error) {
    console.error("âŒ Processing failed:", error);
    res.status(500).json({
      error: "Audio processing failed",
      details: error.message,
      lang
    });
  } finally {
    // Clean up temporary files
    try {
      if (fs.existsSync(filePath)) {
        fs.unlinkSync(filePath);
        console.log("ðŸ—‘ï¸ Cleaned up original file");
      }
      if (fs.existsSync(audioPath)) {
        fs.unlinkSync(audioPath);
        console.log("ðŸ—‘ï¸ Cleaned up converted file");
      }
    } catch (cleanupError) {
      console.error("âš ï¸ Cleanup error:", cleanupError);
    }
  }
});

// Health check endpoint
router.get("/health", (req, res) => {
  res.json({
    status: "âœ… API is running",
    mode: "Mock Transcription",
    timestamp: new Date().toISOString(),
    supportedLanguages: Object.keys(mockResponses),
    version: "1.0.0"
  });
});

// Demo endpoint to test different languages
router.get("/demo/:lang?", (req, res) => {
  const lang = req.params.lang || "en";
  const mockText = mockResponses[lang] || mockResponses.en;
  
  res.json({
    lang,
    text: mockText,
    type: "demo",
    note: "This is a demo response without audio processing"
  });
});

// List supported languages
router.get("/languages", (req, res) => {
  res.json({
    supportedLanguages: [
      { code: "en", name: "English" },
      { code: "bn", name: "Bengali" },
      { code: "hi", name: "Hindi" },
      { code: "pt", name: "Portuguese" },
      { code: "ko", name: "Korean" },
      { code: "banglish", name: "Banglish" }
    ],
    defaultLanguage: "en"
  });
});

module.exports = router;
